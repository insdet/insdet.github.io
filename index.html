<!DOCTYPE html>
<html>
  
<head>
  <meta charset="utf-8">
  <meta name="description" content="">
  <meta property="og:title" content="Object Instance Detection" />
  <meta property="og:description" content="" />
  <meta property="og:url" content="" />
  <meta name="keywords" content="InsDet">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <title>InsDet </title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>


<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Object Instance Detection</h1>
            <h4 class="is-size-5 publication-authors">
              in conjunction with the 5th Workshop on <a href="https://vplow.github.io/vplow_5th.html" target="_blank">VPLOW</a>, CVPR 2025 in Nashville, USA.
            </h4>
            
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Dataset Link -->
                <span class="link-block">
                  <a href="https://drive.google.com/drive/folders/1rIRTtqKJGCTifcqJFSVvFshRb-sB0OzP" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa-solid fa-database"></i>
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
                
                <!-- Challenge link -->
                <span class="link-block">
                  <a href="https://eval.ai/web/challenges/challenge-page/2478/overview" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-trophy"></i>
<!--                       <i class="fas fa-trophy-star"></i> -->
<!--                       <i class="fas fa-file-pdf"></i> -->
                    </span>
                    <span>Challenge</span>
                  </a>
                </span>

                <!-- Code link -->
                <span class="link-block">
                  <a href="https://github.com/shenqq377/instance_detection_challenge" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                
              </div> 
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Challenge overview -->
    <section class="section hero is-light2">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Overview</h2>
            <img src="static/pics/site/objdet-insdet.png" alt="1" style="width: auto; height: auto; display: block; margin: 0 auto;"/> 
            <div class="content has-text-justified">
              <p style="text-align: justify;">
                Instance Detection (InsDet) is a practically important task in robotics applications, e.g., elderly-assistant robots need to 
                fetch specific items from a cluttered kitchen, micro-fulfillment robots for the retail need to pick items from mixed boxes or 
                shelves. Different from Object Detection (ObjDet) detecting all objects belonging to some predefined classes, InsDet aims to 
                detect specific object instances defined by some examples capturing the instance from multiple views.
              </p>    
              <p style="text-align: justify;">              
                This year, we plan to run a competition on our InsDet dataset, which is the instance detection benchmark dataset which is larger 
                in scale and more challenging than existing InsDet datasets. The major strengths of our InsDet dataset over prior InsDet datasets 
                include (1) both high-resolution profile images of object instances and high-resolution testing images from more realistic indoor 
                scenes, simulating real-world indoor robots locating and recognizing object instances from a cluttered indoor scene in a distance 
                (2) a realistic unified InsDet protocol to foster the InsDet research. 
              </p>         
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End challenge overview -->
<!--               Participants in this challenge will be tasked with predicting the bounding boxes for each given instance from testing images. This exciting opportunity allows researchers, students, and data scientists to apply their expertise in computer vision and machine learning to address instance detection problem. We refer participants to the user guide for details. -->


  <!-- Dates overview -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Important Dates</h2>
            <div class="content has-text-justified">
              <p style="text-align: justify;">
                <li><s>March 24, 2025, InsDet (6.60 GB) will be released.</s></li>
                <li><s>March 24, 2025, EvalAI server will be open.</s></li>
                <li><s>May 1, 2025, Scenes Test (2.43 GB) will be released.</s></li>
                <li>May 5, 2025, Evaluation scripts will be uploaded to github repo.</li>
                <li>June 2, 2025, Challenge will be closed.</li>
                <li>June 3, 2025, Invitation will be sent to some participants for presenting at the workshop.</li>
                <li>June 11/12, 2025, Workshop day.</li>   
              </p>      
            </div>
          </div>
        </div>
      </div>
    </section>
  <!-- End dates overview -->


  <!-- Dataset overview -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Dataset</h2>
            <div class="content has-text-justified">
              <h3>Dataset</h3>
              <p style="text-align: justify;">
                The dataset contains 100 object instances with multi-view profile images, 200 pure background images and 160 scene images. 
                Participants can download the dataset from the <a href="https://drive.google.com/drive/folders/1rIRTtqKJGCTifcqJFSVvFshRb-sB0OzP?usp=sharing">InsDet</a> dataset.
              
              <ol>
                <li><b>Objects.</b> 100 different Object instances. Each profile image has a resolution of 3072&times;3072 pixels (some instances are 3456&times;3456). 
                  Each instance is captured at 24 rotation positions (every 15&deg; in azimuth) with a 45&deg; elevation view.</li>
                <li><b>Background.</b> 200 high-resolution background images of indoor scenes that do not include any given instances from Objects.</li>
                <li><b>Scenes.</b> 160 high-resolution images (6144&times;8192) in cluttered scenes, where some instances are placed in reasonable locations. 
                  We tag these images as <i>easy</i> or <i>hard</i> based on scene clutter and object occlusion levels.</li>
              </ol>                
              </p>    
            </div>
          </div>
        </div>
      </div>
    </section>
  <!-- End dataset overview -->


  <!-- Dataset overview -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Benchmarking Protocol</h2>
            <div class="content has-text-justified">
              <h3>Dataset</h3>
              <p style="text-align: justify;">
                <ol>
                  <li><b>Goal.</b> Developing instance detectors using profile images and optionally some random background images. 
                    The detector should detect object instances of interest in real-world testing images.</li>
                  <li><b>Environment for model development.</b>
                    <ol type="a">
                      <li>A set of object instances, each of which has some visual examples captured from multiple views. 
                        Participants should develop a model to successfully detect these object instances.</li>
                      <li>Some random background images (not used in testing). Participants might use them to synthesize images. 
                        Participants can also download and use other external background images in training.</li>
                    </ol>
                  </li>
                  <li><b>Environment for testing.</b> Real-world indoor scene images, in which participants' algorithms should 
                    detect object instances of interest.</li>
                </ol>
                <b>Importantly, participants are not allowed to develop any instance detectors on the Real-world indoor scene images we provided.</b> 
                Furthermore, for participants who are invited for a presentation, we might ask for your code and models for verification. 
              </p>    
            </div>
          </div>
        </div>
      </div>
    </section>
  <!-- End dataset overview -->
  


          <h3></h3>

          <br>
          <h3>Evaluation</h3>
          Following the COCO dataset [8], we tag testing object instances as small, medium, and large according to their bounding box area. The following 12 metrics are used for characterizing the performance of an instance detector on InsDet dataset. Additionally, we will also evaluate AP on easy and hard scenes separately.
          <br>
          <div class="center">
            <img alt="fig1" src="https://raw.githubusercontent.com/insdet/insdet.github.io/main/static/pics/site/evaluation_metrics.png">
          </div>          
        </div>
      </section>
    </div>
  </section>
  
  
 <section class="section" id="Organizers">
    <div class="container is-max-desktop content">
      <h2 class="title" id="organizers">Organizers</h2>
      <div class="columns is-centered is-variable is-0">
        <div style="display: flex">
          <div style="width:25%; justify-content: center">
            <a href="https://shenqq377.github.io/">
              <img alt="Qianqian Shen" src="static/pics/people/qianqian-shen.png" height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
            </a><br>
            <a href="https://shenqq377.github.io/">Qianqian Shen</a><br>
            Zhejiang University
          </div>
        
          <div style="width:7.5%">
          </div>
       
          <div style="width:25%; justify-content: center">
            <a href="https://ics.uci.edu/~yunhaz5/">
              <img alt="Yunhan Zhao" src="static/pics/people/yunhan-zhao.png"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
            </a><br>
            <a href="https://ics.uci.edu/~yunhaz5/">Yunhan Zhao</a><br>
            University of California, Irvine
          </div>

          <div style="width:7.5%">
          </div>
       
          <div style="width:25%; justify-content: center">
            <a href="https://aimerykong.github.io/">
              <img alt="Yunhan Zhao" src="static/pics/people/shu.jpg"   height="200"  width ="200" style =  "border-radius: 50%; object-fit: cover; ">
            </a><br>
            <a href="https://aimerykong.github.io/">Shu Kong</a><br>
            University of Macau
          </div>
          
          <div style="width:7.5%">
          </div>
        </div>
      </div>
    </div>
  </section>

  <footer class="footer">
    <div class="container">
      <div class="content">
        <p>
          It borrows the source code of <a href="https://github.com/nerfies/nerfies.github.io">this website</a>.
          We would like to thank Utkarsh Sinha and Keunhong Park.
        </p>
      </div>
    </div>
  </footer>

</body>
<script src="js/jquery-2.1.1.js"></script>
<script src="js/jquery.mobile.custom.min.js"></script> <!-- Resource jQuery -->
<script src="js/main.js"></script> <!-- Resource jQuery -->

</html>
